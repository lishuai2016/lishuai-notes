#Tomcat的性能与最大并发数


默认150并发，最大1000

##1、Tomcat并发数概述
当一个进程有 500 个线程在跑的话，那性能已经是很低很低了。Tomcat 默认配置的最大请求数是 150，也就是说同时支持 150 个并发，
当然了，也可以将其改大。
当某个应用拥有 250 个以上并发的时候，应考虑应用服务器的集群。
具体能承载多少并发，需要看硬件的配置，CPU 越多性能越高，分配给 JVM 的内存越多性能也就越高，但也会加重 GC 的负担。
操作系统对于进程中的线程数有一定的限制：
Windows 每个进程中的线程数不允许超过 2000
Linux 每个进程中的线程数不允许超过 1000
另外，在 Java 中每开启一个线程需要耗用 1MB 的 JVM 内存空间用于作为线程栈之用。

Tomcat的最大并发数是可以配置的，实际运用中，最大并发数与硬件性能和CPU数量都有很大关系的。
更好的硬件，更多的处理器都会使Tomcat支持更多的并发。
Tomcat 默认的 HTTP 实现是采用阻塞式的 Socket 通信，每个请求都需要创建一个线程处理。这种模式下的并发量受到线程数的限制，
但对于 Tomcat 来说几乎没有 BUG 存在了。
Tomcat 还可以配置 NIO 方式的 Socket 通信，在性能上高于阻塞式的，每个请求也不需要创建一个线程进行处理，并发能力比前者高。但没有阻塞式的成熟。
这个并发能力还与应用的逻辑密切相关，如果逻辑很复杂需要大量的计算，那并发能力势必会下降。
如果每个请求都含有很多的数据库操作，那么对于数据库的性能也是非常高的。
对于单台数据库服务器来说，允许客户端的连接数量是有限制的。
并发能力问题涉及整个系统架构和业务逻辑。
系统环境不同，Tomcat版本不同、JDK版本不同、以及修改的设定参数不同。并发量的差异还是满大的。
maxThreads="1000" 最大并发数 
minSpareThreads="100"///初始化时创建的线程数
maxSpareThreads="500"///一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程。
acceptCount="700"// 指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理



并发用户数和QPS两个概念没有直接关系，但是如果要说QPS时，一定需要指明是多少并发用户数下的QPS，
否则豪无意义，因为单用户数的40QPS和20并发用户数下的40QPS是两个不同的概念。

前者说明该应用可以在一秒内串行执行40个请求，而后者说明在并发20个请求的情况下，一秒内该应用能处理40个请求，
当QPS相同时，越大的并发用户数，代表了网站并发处理能力越好。对于当前的web服务器，其处理单个用户的请求肯定戳戳有余，
这个时候会存在资源浪费的情况（一方面该服务器可能有多个cpu，但是只处理单个进程，另一方面，在处理一个进程中，有些阶段可能是IO阶段，
这个时候会造成CPU等待，但是有没有其他请求进程可以被处理）。而当并发数设置的过大时，每秒钟都会有很多请求需要处理，会造成进程（线程）频繁切换，
反正真正用于处理请求的时间变少，每秒能够处理的请求数反而变少，同时用户的请求等待时间也会变大，甚至超过用户的心理底线。
所以在最小并发数和最大并发数之间，一定有一个最合适的并发数值，在并发数下，QPS能够达到最大。
但是，这个并发并非是一个最佳的并发，因为当QPS到达最大时的并发，可能已经造成用户的等待时间变得超过了其最优值，
所以对于一个系统，其最佳的并发数，一定需要结合QPS，用户的等待时间来综合确定。

上面这张图是应用其他人的关于并发用户数，QPS，用户平均等待时间的一张关系图，对于实际的系统，也应该是对于不同的并发数，
进行多次测试，获取到这些数值后，画出这样一张图出来，以便于分析出系统的最佳并发用户数。


## 2、Tomcat的优化分成两块

### 2.1、 Tomcat启动命令行中的优化参数即JVM优化
Tomcat 的启动参数位于tomcat的安装目录\bin目录下，如果你是Linux操作系统就是catalina.sh文件，
如果你是Windows操作系统那么 你需要改动的就是catalina.bat文件

### 2.2、 Tomcat容器自身参数的优化（这块很像ApacheHttp Server）

各种Web容器，如Tomcat，Resion，Jetty等都有自己的线程池（可在配置文件中配置），所以在客户端进行请求调用的时候，
程序员不用针对Client的每一次请求，都新建一个线程。而容器会自动分配线程池中的线程，提高访问速度。



## 3、Tomcat的server.xml配置Tomcat线程池以使用高并发连接
1.打开共享的线程池：
<Service name="Catalina">
  <!--The connectors can use a shared executor, you can define one or more named thread pools-->
    <Executor name="tomcatThreadPool" namePrefix="catalina-exec-"
    maxThreads="1000" minSpareThreads="50" maxIdleTime="600000"/>
默认前后是注释<!-- -->掉的，去掉就可以了。
重要参数说明：
name：共享线程池的名字。这是Connector为了共享线程池要引用的名字，该名字必须唯一。默认值：None；
namePrefix:在JVM上，每个运行线程都可以有一个name 字符串。这一属性为线程池中每个线程的name字符串设置了一个前缀，Tomcat将把线程号追加到这一前缀的后面。默认值：tomcat-exec-；
maxThreads：该线程池可以容纳的最大线程数。默认值：200；
maxIdleTime：在Tomcat关闭一个空闲线程之前，允许空闲线程持续的时间(以毫秒为单位)。只有当前活跃的线程数大于minSpareThread的值，才会关闭空闲线程。默认值：60000(一分钟)。
minSpareThreads：Tomcat应该始终打开的最小不活跃线程数。默认值：25。
threadPriority：线程的等级。默认是Thread.NORM_PRIORITY

2. 在Connector中指定使用共享线程池：
<Connector executor="tomcatThreadPool"
           port="8080" protocol="HTTP/1.1"
               connectionTimeout="20000"
               redirectPort="8443"
           minProcessors="5"
           maxProcessors="75"
           acceptCount="1000"/>

重要参数说明：
executor：表示使用该参数值对应的线程池；
minProcessors：服务器启动时创建的处理请求的线程数；
maxProcessors：最大可以创建的处理请求的线程数；
acceptCount：指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理。





## 4、Tomcat线程池实现
1、使用APR的Pool技术，使用了JNI。
Tomcat从5.5.17开始，为了提高响应速度和效率，使用了Apache Portable Runtime(APR)作为最底层，
使用了APR中包含Socket、缓冲池等多种技术，性能也提高了。APR也是Apache HTTPD的最底层。
 
2、使用Java实现的Thread Pool。
ThreadPool默认创建了5个线程，保存在一个200维的线程数组中，创建时就启动了这些线程，当然在没有请求时，
它们都处理“等待”状态（其实就是一个while循环，不停的等待notify）。如果有请求时，空闲线程会被唤醒执行用户的请求。

具体的请求过程是： 服务启动时，创建一个一维线程数组（maxThread＝200个），并创建空闲线程(minSpareThreads＝5个)随时等待用户请求。 
当有用户请求时，调用 threadpool.runIt(ThreadPoolRunnable)方法，将一个需要执行的实例传给ThreadPool中。
其中用户需要执行的 实例必须实现ThreadPoolRunnable接口。 ThreadPool 首先查找空闲的线程，如果有则用它运行要执行的ThreadPoolRunnable；
如果没有空闲线程并且没有超过maxThreads，就一次性创建 minSpareThreads个空闲线程；如果已经超过了maxThreads了，就等待空闲线程了。
总之，要找到空闲的线程，以便用它执行实例。找到后，将该线程从线程数组中移走。 接着唤醒已经找到的空闲线程，
用它运行执行实例（ThreadPoolRunnable）。 运行完ThreadPoolRunnable后，就将该线程重新放到线程数组中，作为空闲线程供后续使用。
由此可以看出，Tomcat的线程池实现是比较简单的，ThreadPool.java也只有840行代码。用一个一维数组保存空闲的线程，
每次以一个较小步伐（5个）创建空闲线程并放到线程池中。使用时从数组中移走空闲的线程，用完后，再“归还”给线程池。

      
总结： 
tomcat5.5.10以上版本开始支持apr，支持通过apache runtime module进行JNI调用，使用本地代码来加速网络处理。
如果不使用apr之前，Tomcat的Servlet线程池使用的是阻塞IO的模式，使用apr之后，线程池变成了 NIO的非阻塞模式，
而且这种NIO还是使用了操作系统的本地代码，看tomcat文档上面的说法是，极大提升web处理能力，不再需要专门放一个web server处理静态页面了。 
我自己直观的感受是，不用apr之前，你配置多少个等待线程，tomcat就会启动多少个线程挂起等待，使用apr以后，不管你配置多少，
就只有几个NIO调度的线程，这一点你可以通过kill -3 PID，然后察看log得知。
假设不使用apr，可能端口的线程调度能力比较差，所以通过iptables进行端口转发，让两个端口去分担一个端口的线程调度，
就有可能减少线程调度的并发，从而提高处理能力，减少资源消耗。
 








## 问题
Q:现在有这样一个需求，在一秒中有3万的支付订单请求，有什么比较好的解决方案吗？
PS:我们数据库用的是oracle 程序是java spring mybatis dubbo mq等技术，现在有这样一个场景 高并发写 在一秒中有3万的支付订单请求有什么比较好的解决方案吗？
主要优化哪方面
 
 

1. 首先要解决掉数据库的压力，3万qps对应的磁盘 iops 很大，不过现在好的 SSD 能提供很好的 iops, 
比如这款： ARK | Intel® SSD DC P3700 Series (800GB, 2.5in PCIe 3.0, 20nm, MLC) 单盘 90000 IOPS，
应该能撑住你的数据库，考虑到主备，以及你的sharding需求，3-9 台数据库机器，高内存，高CPU，SSD磁盘应该能抗住

2. 业务逻辑这一层: Java 系，用线程来抗并发的，如果业务逻辑不太复杂，那么基本能做到 100ms 内响应，那么 30000qps,
 对应的是 3000并发线程，这部分设计的时候记得保持无状态，单台支撑 300-1000 并发没问题，加上一倍的冗余，那么 6~20 台业务型机器可以抗住。

3. 缓存层: 支付订单一般对缓存需求不高，但缓存层一般都会有，避免把查询压力压到数据库，简单两台缓存，
或者缓存平行部署在业务型机器上都可以解决，具体看你的情况了。

4. 接入层: nginx 做LVS就可以了，记得 backlog 配大点就可以了, 3万qps, 假设单个请求的数据在 10KB 左右，那么是 300MB/s，
如果是千兆机，每台4网卡，两内两外，加上冗余，我会部署4台入口机，如果是万兆机，两台做主备（心跳或者LVS)即可。

当然，魔鬼在细节，做好机器的监控，慢请求的监控，日志的汇聚与分析。然后逐步推进服务的 SOA 化来降低复杂度。
留一台业务机打小流量来做线上测试。优化JVM运行参数，等等，要做的事情还很多。



从交易角度来看，各种高并发系统可以粗略分为两大类：交易驱动的系统，内容驱动的系统。其中：
交易驱动的系统：包括支付系统、电信计费系统、银行核心交易系统等，此类系统强调数据库事务的ACID原则。
内容驱动的系统：包括SNS、微博、门户、视频、搜索引擎等系统，此类系统对数据库事务ACID的关注不是第一位的，
更强调CAP原则：Consistency（一致性）， Availability（可用性），Partition tolerance（分区容错性）。

与此对应，交易驱动的系统与内容驱动的系统在系统优化方法最大的差异在于：
交易驱动的系统：强调事务的ACID，按照CAP原则做选择，更强调CA（Consistency（一致性）和Availability（可用性）；
因此交易驱动的系统一般在核心交易上选择关系型数据库（包括采用内存数据库、缓存等涉及事务问题），当然这就导致交易系统最大的瓶颈一般都在关系数据库上。
内容驱动的系统：可以在CAP之间根据业务需要做选择三选二，因此一般选择NOSQL为主、RDBMS为辅的方案。

在优化策略上，内容驱动的系统采用的诸多优化手段交易驱动的系统也可以采用，这里重点说一下因事务导致的业务复杂性的处理。
3万笔/每秒这个级别的交易订单这个量级说实话挺大，但即便如此，也有诸多可优化的空间。由于题主未对具体场景说明，只能假定是典型的交易驱动系统，一些思考点：
1、3万笔/每秒是峰值最大交易量还是持续交易量？
2、3万笔/每秒是同一类型的订单还是诸多种类型的订单？
3、业务能否做拆分，例如从功能、从区域、从优先级等角度？
4、支付订单是实时交易还是非实时交易，能否延时入库？
5、支付订单能否延时批量处理？
6、支付订单是否涉及热点账户问题，也即对同一账户会有多个并发请求对其属性（例如账户余额）进行操作？





